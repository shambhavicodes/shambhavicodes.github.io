<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Shambhavi Mishra | Vision Language Talks</title>
    <meta name="description" content="Reading Group: Vision Language Talks">
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css">
    <link rel="stylesheet" href="/assets/css/main.css">
    <style>
      .talk-entry {
        display: flex;
        align-items: center;
        margin-bottom: 20px;
      }
      .talk-entry img {
        max-width: 200px;
        border-radius: 8px;
        margin-right: 15px;
      }
      .talk-details {
        flex: 1;
      }
    </style>
  </head>
  <body class="fixed-top-nav">
    <header>
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">
            <span class="font-weight-bold">Shambhavi</span> Mishra
          </a>
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>
          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">
              <li class="nav-item"><a class="nav-link" href="/">about</a></li>
              <li class="nav-item"><a class="nav-link" href="/experience/">experience</a></li>
              <li class="nav-item"><a class="nav-link" href="/publications/">research</a></li>              
              <li class="nav-item active"><a class="nav-link" href="/reading-group/">reading group</a></li>
            </ul>
          </div>
        </div>
      </nav>
    </header>
    <div class="container mt-5">
      <div class="post">
        <header class="post-header">
            <h1 class="post-title">Vision Language Talks</h1>
            <p class="post-description">
                Want to keep up with the rapidly evolving world of AI research? Join our reading group, where we collaborate with authors to delve deep into their work, promote their research, and explore potential collaborations. Many sessions include primers on various topics. With over 50 past sessions, you can explore our content on our <a href="https://www.youtube.com/channel/UCseJlTlqQ2jfW66r-fOYaNg" target="_blank" style="color: blue;">YouTube channel</a> and join our professional community on <a href="https://www.linkedin.com/company/computer-vision-talks/" target="_blank" style="color: blue;">LinkedIn</a>. Stay updated by signing up for our mailing list <a href="https://forms.gle/JZK3RAnAgsGVUTsCA" target="_blank" style="color: blue;">here</a>.
            </p>
          </header>
        <article>
            <!-- Talk Entries -->
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=08OORYmrYio" target="_blank">
                <img src="https://img.youtube.com/vi/08OORYmrYio/hqdefault.jpg" alt="Graph-enhanced Large Language Models">
              </a>
              <div class="talk-details">
                <h5>Graph-enhanced Large Language Models</h5>
                <p><strong>Author:</strong> Fangru Lin, DPhil NLP @UniversityOfOxford</p>
                <p><strong>TL;DR:</strong> This talk presents "Plan Like a Graph" (PLaG), a novel technique that integrates graphs with natural language prompts to enhance large language models' (LLMs) performance in asynchronous plan reasoning tasks. Despite improvements, challenges persist as task complexity increases, highlighting the limitations of current LLMs in simulating digital devices. </p>
                <p><strong>Keywords:</strong> Graph-enhanced LLMs, asynchronous planning, Plan Like a Graph (PLaG)</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=V-mxeWZjCUo" target="_blank">
                <img src="https://img.youtube.com/vi/V-mxeWZjCUo/hqdefault.jpg" alt="Computationally Budgeted Continual Learning">
              </a>
              <div class="talk-details">
                <h5>Computationally Budgeted Continual Learning</h5>
                <p><strong>Author:</strong> Ameya Prabhu PhD@Torr Vision Group, UniversityOfOxford</p>
                <p><strong>TL;DR:</strong> This presentation explores continual learning under computational constraints, emphasizing the need for models to adapt to new data streams efficiently. The study reveals that traditional continual learning methods struggle when computational budgets are limited, underscoring the importance of developing strategies that balance performance with resource constraints.</p>
                <p><strong>Keywords:</strong> Continual learning, computational budget, data streams, model adaptation, resource constraints</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=lioXFB49wow" target="_blank">
                <img src="https://img.youtube.com/vi/lioXFB49wow/hqdefault.jpg" alt="Learning Object Recognition with Rich Language Descriptions">
              </a>
              <div class="talk-details">
                <h5>Learning Object Recognition with Rich Language Descriptions</h5>
                <p><strong>Author:</strong> Liunian Li, PhD@UCLA</p>
                <p><strong>TL;DR:</strong> This talk discusses methods for enhancing object recognition systems by incorporating detailed language descriptions, aiming to improve model accuracy and robustness in understanding visual content.​
                </p>
                <p><strong>Keywords:</strong> Object recognition, language descriptions, visual understanding, model accuracy</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=sdp6oZtxW4c" target="_blank">
                <img src="https://img.youtube.com/vi/sdp6oZtxW4c/hqdefault.jpg" alt="Memory-Economic Continual Test-TimeAdaptation">
              </a>
              <div class="talk-details">
                <h5>Memory-Economic Continual Test-TimeAdaptation</h5>
                <p><strong>Author:</strong> Junyuan Hong, PhD @MichiganStateUni, Intern@SonyAI</p>
                <p><strong>TL;DR:</strong> The presentation introduces approaches for continual test-time adaptation that are memory-efficient, enabling models to adapt to new data without extensive computational resources.​</p>
                <p><strong>Keywords:</strong> Continual learning, test-time adaptation, memory efficiency, model adaptability</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=zH7enqkU-E0" target="_blank">
                <img src="https://img.youtube.com/vi/zH7enqkU-E0/hqdefault.jpg" alt="On the Impact of Estimating Example Difficulty with Chirag Agarwal, Research Scientist@Adobe">
              </a>
              <div class="talk-details">
                <h5>On the Impact of Estimating Example Difficulty </h5>
                <p><strong>Author:</strong> Chirag Agarwal, Research Scientist@Adobe</p>
                <p><strong>TL;DR:</strong> This talk examines how assessing the difficulty of training examples can influence model training and performance, providing insights into curriculum learning strategies.</p>
                <p><strong>Keywords:</strong> Example difficulty estimation, curriculum learning, model training, performance optimization</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=fzeu8g34EN4" target="_blank">
                <img src="https://img.youtube.com/vi/fzeu8g34EN4/hqdefault.jpg" alt="SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models">
              </a>
              <div class="talk-details">
                <h5>SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models</h5>
                <p><strong>Author:</strong> Omiros Pantazis PhD @UCL.
                </p>
                <p><strong>TL;DR:</strong> This work introduces SVL-Adapter, a method that enhances vision-language models like CLIP by integrating self-supervised learning. This approach improves classification accuracy, especially in low-shot settings, by combining the strengths of vision-language pretraining with self-supervised representation learning.</p>
                <p><strong>Keywords:</strong> Vision-language models, self-supervised learning, low-shot learning, model adaptation </p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=M8r-w__aL10" target="_blank">
                <img src="https://img.youtube.com/vi/M8r-w__aL10/hqdefault.jpg" alt="Master of All : Simultaneous Generalization of Urban-Scene Segmentation">
              </a>
              <div class="talk-details">
                <h5>Master of All : Simultaneous Generalization of Urban-Scene Segmentation</h5>
                <p><strong>Author:</strong> Nikhil Reddy @PhD student at UQ-IIT Delhi Research Academy </p>
                <p><strong>TL;DR:</strong> The "Master of ALL" (MALL) technique is a test-time adaptation method designed to improve semantic segmentation of urban scenes across various adverse weather conditions. MALL updates pre-trained models during inference to enhance performance without requiring access to source data.​</p>
                <p><strong>Keywords:</strong> Semantic segmentation, test-time adaptation, adverse weather conditions, domain generalization</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=8DKbESVzqvo" target="_blank">
                <img src="https://img.youtube.com/vi/8DKbESVzqvo/hqdefault.jpg" alt="Contrastive Test-Time Adaptation @CVPR22">
              </a>
              <div class="talk-details">
                <h5>Contrastive Test-Time Adaptation</h5>
                <p><strong>Author:</strong> Dian Chen @ToyotaResearchInstitute</p>
                <p><strong>TL;DR:</strong>  This work introduces AdaContrast, a novel approach to test-time adaptation using self-supervised contrastive learning combined with an online pseudo-labeling scheme. It enhances target feature learning and achieves state-of-the-art performance on major benchmarks, offering benefits like memory efficiency and better model calibration.​</p>
                <p><strong>Keywords:</strong> Test-Time Adaptation, Contrastive Learning, Pseudo-Labeling, Domain Adaptation, Self-Supervised Learning​</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=H4uHhkRMECI" target="_blank">
                <img src="https://img.youtube.com/vi/H4uHhkRMECI/hqdefault.jpg" alt="Spatio-temporal Relation Modeling for Few-shot Action Recognition">
              </a>
              <div class="talk-details">
                <h5>Spatio-temporal Relation Modeling for Few-shot Action Recognition</h5>
                <p><strong>Author:</strong> Anirudh Thatipelli, PhD @CRCV, UCF</p>
                <p><strong>TL;DR:</strong> The authors propose STRM, a framework that enhances class-specific feature discriminability while learning higher-order temporal representations. It introduces a spatio-temporal enrichment module that aggregates spatial and temporal contexts and achieves state-of-the-art results on few-shot action recognition benchmarks.​</p>
                <p><strong>Keywords:</strong> Few-Shot Learning, Action Recognition, Spatio-Temporal Modeling, Feature Enrichment, Temporal Relations</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=2rG7NGXJ6PY" target="_blank">
                <img src="https://img.youtube.com/vi/2rG7NGXJ6PY/hqdefault.jpg" alt="Margin-based Label Smoothing for Network Calibration, CVPR 2022">
              </a>
              <div class="talk-details">
                <h5>Margin-based Label Smoothing for Network Calibration, CVPR 2022</h5>
                <p><strong>Author:</strong> Bingyuan Liu @Amazon</p>
                <p><strong>TL;DR:</strong> This work presents a margin-based label smoothing technique aimed at improving network calibration. By adjusting the label smoothing process based on class margins, the method enhances the reliability of model predictions.​
                </p>
                <p><strong>Keywords:</strong>  Label Smoothing, Network Calibration, Margin-Based Techniques, Model Reliability</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=g9YCXqwYL-A" target="_blank">
                <img src="https://img.youtube.com/vi/g9YCXqwYL-A/hqdefault.jpg" alt="Role Of Shannon Entropy As A Regularizer Of DeepNNs With Prof Jose Dolz @ETS Montreal">
              </a>
              <div class="talk-details">
                <h5>Role Of Shannon Entropy As A Regularizer Of DeepNNs </h5>
                <p><strong>Author:</strong> Prof. Jose Dolz, École de technologie supérieure (ETS) Montreal</p>
                <p><strong>TL;DR:</strong> This talk explores the application of Shannon Entropy as a regularization technique in deep neural networks, aiming to improve model robustness and generalization by managing uncertainty during training.</p>
                <p><strong>Keywords:</strong> Shannon Entropy, regularization, deep neural networks, model robustness</p>
              </div>
            </div>
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=CnsctWTv2C4" target="_blank">
                  <img src="https://img.youtube.com/vi/CnsctWTv2C4/hqdefault.jpg" alt="Self-Supervising Occlusions For Vision">
                </a>
                <div class="talk-details">
                  <h5>Self-Supervising Occlusions For Vision</h5>
                  <p><strong>Author:</strong> Dinesh Reddy, PhD @CMU Robotics</p>
                  <p><strong>TL;DR:</strong> This talk addresses the challenges posed by occlusions in visual scenes and introduces self-supervised methodologies to predict and handle occluded regions using multi-view supervision and longitudinal data.</p>
                  <p><strong>Keywords:</strong> Occlusions, Self-Supervised Learning, Multi-View Supervision, Longitudinal Data</p>
                </div>
              </div>
              
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=SWCTMmzmY6o" target="_blank">
                  <img src="https://img.youtube.com/vi/SWCTMmzmY6o/hqdefault.jpg" alt="Mathematical Models of Brain Connectivity and Behavior">
                </a>
                <div class="talk-details">
                  <h5>Mathematical Models of Brain Connectivity and Behavior</h5>
                  <p><strong>Author:</strong> Niharika S. D’Souza @IBM Research, Almaden</p>
                  <p><strong>TL;DR:</strong> This presentation explores the use of mathematical and machine learning models to link the structural and functional organization of the brain with behavioral patterns, aiming to predict clinical severity from neuroimaging data.</p>
                  <p><strong>Keywords:</strong> Brain Connectivity, Behavior Prediction, Machine Learning, Neuroimaging, Clinical Severity</p>
                </div>
              </div>
              
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=ksuAW9PbXS8" target="_blank">
                  <img src="https://img.youtube.com/vi/ksuAW9PbXS8/hqdefault.jpg" alt="Mixture-Based Feature Space Learning for Few-Shot Classification">
                </a>
                <div class="talk-details">
                  <h5>Mixture-Based Feature Space Learning for Few-Shot Classification</h5>
                  <p><strong>Author:</strong> Arman Afrasiyabi @MILA</p>
                  <p><strong>TL;DR:</strong> This talk introduces a mixture-based approach to feature space learning, enhancing the performance of few-shot classification tasks by effectively modeling complex data distributions.</p>
                  <p><strong>Keywords:</strong> Few-Shot Classification, Feature Space Learning, Mixture Models, Machine Learning</p>
                </div>
              </div>              
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=i6ZbnnKIACI" target="_blank">
                <img src="https://img.youtube.com/vi/i6ZbnnKIACI/hqdefault.jpg" alt="Generalized and Incremental Few-Shot Learning by Explicit Learning & Calibration without Forgetting">
              </a>
              <div class="talk-details">
                <h5>Generalized and Incremental Few-Shot Learning by Explicit Learning & Calibration without Forgetting</h5>
                <p><strong>Author:</strong> Anna Kukleva @PhD at Computer Vision and Machine Learning department at Max Plank Institute for Informatics </p>
                <p><strong>TL;DR:</strong> What is few-shot learning? What is generalized few-shot learning? What are the difficulties? Our framework to address these difficulties? Extension to incremental learning?</p>
                <p><strong>Keywords:</strong> Few-shot learning, incremental learning, model calibration, catastrophic forgetting</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=0MZxWozdRiM" target="_blank">
                <img src="https://img.youtube.com/vi/0MZxWozdRiM/hqdefault.jpg" alt="Discriminative Region-based Multi-Label Zero-Shot Learning [ICCV 2021] Akshita Gupta @IIAI">
              </a>
              <div class="talk-details">
                <h5>Discriminative Region-based Multi-Label Zero-Shot Learning</h5>
                <p><strong>Author:</strong> Akshita Gupta @IIAI</p>
                <p><strong>TL;DR:</strong> The talk presents a discriminative approach to region-based multi-label zero-shot learning, enabling models to recognize and localize multiple unseen classes simultaneously by leveraging region-level features and semantic embeddings.</p>
                <p><strong>Keywords:</strong> Zero-shot learning, multi-label classification, region-based learning, semantic embeddings</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=0BCb-TsMjXU" target="_blank">
                <img src="https://img.youtube.com/vi/0BCb-TsMjXU/hqdefault.jpg" alt="PAWS : Semi-Supervised Learning of Visual Features">
              </a>
              <div class="talk-details">
                <h5>PAWS : Semi-Supervised Learning of Visual Features</h5>
                <p><strong>Author:</strong> Mido Assran @Facebook AI Research (FAIR) and Mila – Quebec AI Institute.</p>
                <p><strong>TL;DR:</strong> Propose PAWS, a novel method of learning, extending the distance-metric loss used in self-supervised methods such as BYOL and SwAV to a semi-supervised setting
                    Set new state-of-the-art for ResNet-50 on ImageNet trained with either 10% or 1% of the labels, reaching 75% and 66% top-1 respectively (achieved with 4x — 12x less training)
                    Match performance of fully supervised learning with bigger networks, while using 10x fewer labels
                </p>
                <p><strong>Keywords:</strong> Semi-Supervised Learning, Self-Supervised Learning, PAWS, Contrastive Learning, Metric Learning, ImageNet, ResNet-50, BYOL, SwAV, Few-Label Training</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=icUbbsqHjEw" target="_blank">
                <img src="https://img.youtube.com/vi/icUbbsqHjEw/hqdefault.jpg" alt="Using Progressive Context Encoders for Anomaly Detection">
              </a>
              <div class="talk-details">
                <h5>Using Progressive Context Encoders for Anomaly Detection</h5>
                <p><strong>Author:</strong> Quincy Gu @Mayo Clinic</p>
                <p><strong>TL;DR:</strong> label-free anomaly detection pipeline</p>
                <p><strong>Keywords:</strong> Anomaly detection, context encoders, unsupervised learning</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=f60CkU2B0zU" target="_blank">
                <img src="https://img.youtube.com/vi/f60CkU2B0zU/hqdefault.jpg" alt="What Can We Learn From Subtitled Sign Language Data? Gül Varol, Asst. Prof@École des Ponts ParisTech">
              </a>
              <div class="talk-details">
                <h5>What Can We Learn From Subtitled Sign Language Data? Gül Varol, Asst. Prof@École des Ponts ParisTech</h5>
                <p><strong>Author:</strong> Gül Varol, Assistant Professor at École des Ponts ParisTech</p>
                <p><strong>TL;DR:</strong> This talk explores the insights and opportunities presented by subtitled sign language data, focusing on how such data can be utilized to improve sign language recognition and translation systems.</p>
                <p><strong>Keywords:</strong>  Sign language recognition, subtitled data, language translation, multimodal learning</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=M_O3LF0qY1I" target="_blank">
                <img src="https://img.youtube.com/vi/M_O3LF0qY1I/hqdefault.jpg" alt="ViTGAN : Training GANs with Vision Transformers">
              </a>
              <div class="talk-details">
                <h5>ViTGAN : Training GANs with Vision Transformers</h5>
                <p><strong>Author:</strong> Paper Discussion with the Author</p>
                <p><strong>TL;DR:</strong> The presentation introduces ViTGAN, a novel approach that integrates Vision Transformers into Generative Adversarial Networks to enhance image generation quality by capturing long-range dependencies in visual data.</p>
                <p><strong>Keywords:</strong> Vision Transformers, Generative Adversarial Networks, image generation​</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=j0f74Pp6T8A" target="_blank">
                <img src="https://img.youtube.com/vi/j0f74Pp6T8A/hqdefault.jpg" alt="Federated Learning in Vision Tasks">
              </a>
              <div class="talk-details">
                <h5>Federated Learning in Vision Tasks</h5>
                <p><strong>Author:</strong> Umberto Michieli, PhD@Uni of Padova, Intern@Samsung Research</p>
                <p><strong>TL;DR:</strong> Federated Learning (FL) enables distributed model training across decentralized data sources, addressing privacy concerns and data heterogeneity. This talk explores FL's application to computer vision tasks, highlighting challenges like system and statistical heterogeneity, and introduces methods such as FedProto, which leverages prototypical representations to enhance federated optimization.</p>
                <p><strong>Keywords:</strong>  Federated Learning, Distributed Training, Prototypical Representations, Data Privacy​</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=XScUywEx4Pc" target="_blank">
                <img src="https://img.youtube.com/vi/XScUywEx4Pc/hqdefault.jpg" alt="PLOP : Learning continuously without forgetting for Continual SemSeg">
              </a>
              <div class="talk-details">
                <h5>PLOP : Learning continuously without forgetting for Continual SemSeg</h5>
                <p><strong>Author:</strong> Arthur Douillard @DeepMind</p>
                <p><strong>TL;DR:</strong> Continual Semantic Segmentation (CSS) involves updating models to recognize new classes without forgetting previously learned ones. PLOP addresses challenges like catastrophic forgetting and background shift by introducing a multi-scale pooling distillation scheme and an entropy-based pseudo-labeling strategy, significantly improving performance in CSS scenarios.</p>
                <p><strong>Keywords:</strong>  Continual Learning, Semantic Segmentation, Catastrophic Forgetting, Background Shift, Pseudo-Labeling</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=VW-ifhEXm0g" target="_blank">
                <img src="https://img.youtube.com/vi/VW-ifhEXm0g/hqdefault.jpg" alt="An Identifiability Perspective on Representation Learning">
              </a>
              <div class="talk-details">
                <h5>An Identifiability Perspective on Representation Learning</h5>
                <p><strong>Author:</strong> Yash Sharma, PhD@(MPI-​IS)</p>
                <p><strong>TL;DR:</strong> This talk delves into the identifiability aspects of representation learning, discussing conditions under which learned representations can be considered identifiable and the implications for model robustness and interpretability.</p>
                <p><strong>Keywords:</strong> Representation Learning, Identifiability, Model Robustness, Interpretability</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=KhB4OC5Inig" target="_blank">
                <img src="https://img.youtube.com/vi/KhB4OC5Inig/hqdefault.jpg" alt="Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams">
              </a>
              <div class="talk-details">
                <h5>Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams</h5>
                <p><strong>Author:</strong> Matthias De Lange, PhD @KU Leuven</p>
                <p><strong>TL;DR:</strong> The talk addresses the challenge of learning from non-stationary data streams, proposing a method for continual prototype evolution to adapt models online without catastrophic forgetting.</p>
                <p><strong>Keywords:</strong> Continual Learning, Non-Stationary Data, Prototype Evolution, Online Learning</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=5mOELQ8r9NU" target="_blank">
                <img src="https://img.youtube.com/vi/5mOELQ8r9NU/hqdefault.jpg" alt="SeqNet: Learning Descriptors for Hierarchical Place Recognition">
              </a>
              <div class="talk-details">
                <h5>SeqNet: Learning Descriptors for Hierarchical Place Recognition</h5>
                <p><strong>Author:</strong> Sourav Garg, PostDoc @QUT</p>
                <p><strong>TL;DR:</strong> SeqNet introduces a method for learning descriptors tailored for hierarchical place recognition, enhancing the accuracy and efficiency of localization systems in robotics and autonomous vehicles.</p>
                <p><strong>Keywords:</strong> Place Recognition, Descriptor Learning, Hierarchical Localization, Robotics</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=3YLQ3u7Ahkk" target="_blank">
                <img src="https://img.youtube.com/vi/3YLQ3u7Ahkk/hqdefault.jpg" alt="Scale Equivariant Siamese Tracking">
              </a>
              <div class="talk-details">
                <h5>Scale Equivariant Siamese Tracking</h5>
                <p><strong>Author:</strong> Ivan Sosnovik & Artem Moskalev</p>
                <p><strong>TL;DR:</strong> This talk presents a scale-equivariant Siamese network for object tracking, ensuring that the model's predictions are consistent across different scales, thereby improving tracking robustness.</p>
                <p><strong>Keywords:</strong> Object Tracking, Scale Equivariance, Siamese Networks </p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=8tM4BhONHms" target="_blank">
                <img src="https://img.youtube.com/vi/8tM4BhONHms/hqdefault.jpg" alt="Conformal Inference of Counterfactuals and Individual Treatment effects(Stanford)">
              </a>
              <div class="talk-details">
                <h5>Conformal Inference of Counterfactuals and Individual Treatment effects(Stanford)</h5>
                <p><strong>Author:</strong> Lihua Lei, Post Doc at Stanford University</p>
                <p><strong>TL;DR:</strong> The presentation explores conformal inference methods for estimating counterfactuals and individual treatment effects, providing a framework for making reliable causal inferences in observational studies.</p>
                <p><strong>Keywords:</strong> Conformal Inference, Counterfactuals, Treatment Effects, Causal Inference</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=z3TN3V6S4JM" target="_blank">
                <img src="https://img.youtube.com/vi/z3TN3V6S4JM/hqdefault.jpg" alt="Self-Supervised  Few-Shot Learning on Point Clouds(NeurIPS 2020)">
              </a>
              <div class="talk-details">
                <h5>Self-Supervised  Few-Shot Learning on Point Clouds</h5>
                <p><strong>Author:</strong> Charu Sharma, PhD @IIT Hyderabad</p>
                <p><strong>TL;DR:</strong> The talk introduces a self-supervised approach to few-shot learning on point clouds, enabling models to learn representations without extensive labeled data, which is particularly beneficial for 3D vision tasks.​</p>
                <p><strong>Keywords:</strong>Self-Supervised Learning, Few-Shot Learning, Point Clouds, 3D Vision</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=5NeB17-Olp8" target="_blank">
                <img src="https://img.youtube.com/vi/5NeB17-Olp8/hqdefault.jpg" alt="Unsupervised Domain Adaptation for Semantic Segmentation of NIR Images">
              </a>
              <div class="talk-details">
                <h5>Unsupervised Domain Adaptation for Semantic Segmentation of NIR Images</h5>
                <p><strong>Author:</strong>Aayush Tyagi, PhD @IIT-Delhi </p>
                <p><strong>TL;DR:</strong> This presentation discusses techniques for unsupervised domain adaptation in the context of semantic segmentation of Near-Infrared (NIR) images, addressing the challenges posed by domain shifts between visible and NIR spectra.</p>
                <p><strong>Keywords:</strong> Unsupervised Domain Adaptation, Semantic Segmentation, NIR Imaging, Domain Shift</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=V-kPP9buPYU" target="_blank">
                <img src="https://img.youtube.com/vi/V-kPP9buPYU/hqdefault.jpg" alt="GOCor (NeurIPS 2020)">
              </a>
              <div class="talk-details">
                <h5>GOCor : Bringing Globally Optimized Correspondence Volumes into Your Neural Network                </h5>
                <p><strong>Author:</strong> Prune Truong, PhD Student at the Computer Vision Lab of ETH Zurich</p>
                <p><strong>TL;DR:</strong> GOCor introduces a novel approach to correlation-based methods in computer vision, enhancing the performance of tasks like object tracking and alignment by learning optimal correlation filters.</p>
                <p><strong>Keywords:</strong> Correlation Filters, Object Tracking, GOCor</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=s2aqB0HXG24" target="_blank">
                <img src="https://img.youtube.com/vi/s2aqB0HXG24/hqdefault.jpg" alt="Contrastive Learning of Global & Local Features">
              </a>
              <div class="talk-details">
                <h5>Contrastive Learning of Global & Local Features</h5>
                <p><strong>Author:</strong> Krishna Chaitanya, PhD @Computer Vision Lab, ETH Zurich</p>
                <p><strong>TL;DR:</strong> This talk presents strategies to extend the contrastive learning framework for segmentation of volumetric medical images in semi-supervised settings with limited annotations, leveraging domain-specific and problem-specific cues.</p>
                <p><strong>Keywords:</strong> Contrastive learning, medical image segmentation, semi-supervised learning, global and local features</p>
              </div>
            </div>
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=KPOmSCa5hls" target="_blank">
                  <img src="https://img.youtube.com/vi/KPOmSCa5hls/hqdefault.jpg" alt="Forecasting Characteristic 3D Poses of Human Actions">
                </a>
                <div class="talk-details">
                  <h5>Forecasting Characteristic 3D Poses of Human Actions</h5>
                  <p><strong>Author:</strong> Christian Diller, PhD @3D AI Lab at the Technical University of Munich (TUM)</p>
                  <p><strong>TL;DR:</strong> Introduces a probabilistic approach to predict future characteristic 3D poses from short sequence observations, aiming for goal-oriented understanding of human actions.</p>
                  <p><strong>Keywords:</strong> 3D pose forecasting, human motion prediction, probabilistic modeling</p>
                </div>
              </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=0AFWhGMYYbA" target="_blank">
                <img src="https://img.youtube.com/vi/0AFWhGMYYbA/hqdefault.jpg" alt="A Broad Overview of Social Robotics">
              </a>
              <div class="talk-details">
                <h5>A Broad Overview of Social Robotics</h5>
                <p><strong>Author:</strong> Chinmay Mishra, Marie Skłodowska-Curie Actions ITN Fellow</p>
                <p><strong>TL;DR:</strong> This talk provides a comprehensive overview of social robots, discussing their history, physical characteristics, principles to enhance positive public perception, potential threats arising with ubiquity, and their impacts in various industries.</p>
                <p><strong>Keywords:</strong> Social robots, human-robot interaction, ethical considerations, public perception, industry applications</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=eutSnCHfLbw" target="_blank">
                <img src="https://img.youtube.com/vi/eutSnCHfLbw/hqdefault.jpg" alt="Improving Autonomous Driving Pipeline using Graph Neural Networks">
              </a>
              <div class="talk-details">
                <h5>Improving Autonomous Driving Pipeline using Graph Neural Networks</h5>
                <p><strong>Author:</strong> Xinshuo Weng, PhD @Robotics Institute - Carnegie Mellon University                </p>
                <p><strong>TL;DR:</strong> This talk explores the application of graph neural networks to enhance the autonomous driving pipeline, focusing on improving perception, prediction, and planning modules by effectively modeling the relationships between various entities in a driving scenario.</p>
                <p><strong>Keywords:</strong> Autonomous Driving, Graph Neural Networks (GNNs), Perception, Prediction, Planning, Scene Understanding, Object Interactions, Spatiotemporal Modeling, Motion Forecasting, Robotics, Deep Learning</p>
              </div>
            </div>
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=npC7OKJQLCc" target="_blank">
                  <img src="https://img.youtube.com/vi/npC7OKJQLCc/hqdefault.jpg" alt="End to end accelerated MRI acquisition and processing with deep learning">
                </a>
                <div class="talk-details">
                  <h5>End to end accelerated MRI acquisition and processing with deep learning</h5>
                  <p><strong>Author:</strong> Francesco Caliva @Amazon</p>
                  <p><strong>TL;DR:</strong> This talk explores the application of deep learning techniques to accelerate MRI acquisition and processing, aiming to improve efficiency and accuracy in medical imaging workflows.</p>
                  <p><strong>Keywords:</strong> MRI, Deep Learning, Medical Imaging, Accelerated Imaging, Image Processing</p>
                </div>
              </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=W7ZM2U2ds5M" target="_blank">
                <img src="https://img.youtube.com/vi/W7ZM2U2ds5M/hqdefault.jpg" alt="Introduction to Representation learning:  Approaches, Challenges and Applications">
              </a>
              <div class="talk-details">
                <h5>Introduction to Representation learning:  Approaches, Challenges and Applications</h5>
                <p><strong>Author:</strong> Shuyu Lin @University of Oxford </p>
                <p><strong>TL;DR:</strong> This talk introduces the fundamentals of representation learning, covering various approaches, addressing challenges such as interpretability and generalization, and highlighting applications across different domains.</p>
                <p><strong>Keywords:</strong> Representation learning, machine learning, interpretability, generalization, applications</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=m022Ut5dT4I" target="_blank">
                <img src="https://img.youtube.com/vi/m022Ut5dT4I/hqdefault.jpg" alt="Wasserstein Distances for Stereo Disparity Estimation | Divyansh Garg">
              </a>
              <div class="talk-details">
                <h5>Wasserstein Distances for Stereo Disparity Estimation </h5>
                <p><strong>Author:</strong> PhD @Stanford University</p>
                <p><strong>TL;DR:</strong>The fact that this distribution is usually learned indirectly through a regression loss causes further problems in ambiguous regions around object boundaries. We address these issues using a new neural network architecture that is capable of outputting arbitrary depth values, and a new loss function that is derived from the Wasserstein distance between the true and the predicted distributions.</p>
                <p><strong>Keywords:</strong> Stereo disparity estimation, Wasserstein distances, depth perception</p>
              </div>
            </div>
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=HaYJmqZSRzk" target="_blank">
                  <img src="https://img.youtube.com/vi/HaYJmqZSRzk/hqdefault.jpg" alt="Learning a Neural Solver for Multiple Object Tracking">
                </a>
                <div class="talk-details">
                  <h5>Learning a Neural Solver for Multiple Object Tracking</h5>
                  <p><strong>Author:</strong> Guillem Brasó, PhD @Dynamic Vision and Learning group (DVL), Technical University of Munich (TUM)</p>
                  <p><strong>TL;DR:</strong> This talk introduces a novel approach to Multiple Object Tracking (MOT) by leveraging Message Passing Networks (MPNs) within a differentiable framework. By directly operating on graph structures, the method enables global reasoning over detections, leading to improved data association and tracking performance.</p>
                  <p><strong>Keywords:</strong> Multiple Object Tracking, Message Passing Networks, Graph Neural Networks, Data Association, Differentiable Framework</p>
                </div>
              </div>
              
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=M56tKIwmQtM" target="_blank">
                  <img src="https://img.youtube.com/vi/M56tKIwmQtM/hqdefault.jpg" alt="Black Magic in Deep Learning: How Human Skill Impacts Network Training">
                </a>
                <div class="talk-details">
                  <h5>Black Magic in Deep Learning: How Human Skill Impacts Network Training</h5>
                  <p><strong>Author:</strong> Dr. Jan van Gemert, Head of the Computer Vision Lab, Delft University of Technology</p>
                  <p><strong>TL;DR:</strong> This study investigates the subjective human factors in deep learning, focusing on how a user's prior experience impacts the accuracy of network training. Based on a study with 31 participants of varying experience levels, the results show a strong positive correlation between experience and performance, with experienced participants finding better solutions using fewer resources.</p>
                  <p><strong>Keywords:</strong> Deep Learning, Human Factors, Network Training, Hyperparameter Optimization, Machine Learning</p>
                </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=E5nKeEvoAK0" target="_blank">
                <img src="https://img.youtube.com/vi/E5nKeEvoAK0/hqdefault.jpg" alt="Sign Language Translation with Transformers">
              </a>
              <div class="talk-details">
                <h5>Sign Language Translation with Transformers</h5>
                <p><strong>Author:</strong> Kayo Yin, Master's @Language Technologies Institute - Carnegie Mellon University</p>
                <p><strong>TL;DR:</strong> Sign Language Translation (SLT) first uses a Sign Language Recognition (SLR) system to extract sign language glosses from videos. Then, a translation system generates spoken language translations from the sign language glosses. This paper focuses on the translation system and introduces the STMC-Transformer.</p>
                <p><strong>Keywords:</strong> Sign Language Translation, Transformers, Sign Language Recognition (SLR), Natural Language Processing (NLP), Multimodal Learning, Gloss-Based Translation, Sequence-to-Sequence Models, Accessibility</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=5ojspf71RT8" target="_blank">
                <img src="https://img.youtube.com/vi/5ojspf71RT8/hqdefault.jpg" alt="C4Synth: Cross-Caption Cycle-Consistent Text-to-Image Synthesis">
              </a>
              <div class="talk-details">
                <h5>C4Synth: Cross-Caption Cycle-Consistent Text-to-Image Synthesis</h5>
                <p><strong>Author:</strong>Joseph K J, PhD @IIT Hyderabad</p>
                <p><strong>TL;DR:</strong> This talk introduces C4Synth, a framework for text-to-image synthesis that ensures consistency between generated images and their corresponding captions through a cycle-consistent approach.</p>
                <p><strong>Keywords:</strong>Text-to-image synthesis, cycle-consistency, generative models</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=qeqja3zL4eg" target="_blank">
                <img src="https://img.youtube.com/vi/qeqja3zL4eg/hqdefault.jpg" alt="'AdvPC: Transferable Adversarial Perturbations' , 'Towards Analyzing Semantic Robustness of DeepNN'">
              </a>
              <div class="talk-details">
                <h5>'AdvPC: Transferable Adversarial Perturbations' , 'Towards Analyzing Semantic Robustness of DeepNN'</h5>
                <p><strong>Author:</strong> PhD @KAUST Computer Vision Lab (IVUL)</p>
                <p><strong>TL;DR:</strong>These presentations delve into creating adversarial perturbations that transfer across models and analyzing the semantic robustness of deep neural networks, highlighting vulnerabilities and proposing mitigation strategies.​                </p>
                <p><strong>Keywords:</strong>Adversarial perturbations, semantic robustness, deep neural networks, security</p>
              </div>
            </div>
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=mnNuSg0d34s" target="_blank">
                  <img src="https://img.youtube.com/vi/mnNuSg0d34s/hqdefault.jpg" alt="Attributional Robustness Training using Input-Gradient Spatial Alignment">
                </a>
                <div class="talk-details">
                  <h5>Attributional Robustness Training using Input-Gradient Spatial Alignment</h5>
                  <p><strong>Author:</strong> Puneet Mangla, Undergrad @IIT Hyderabad </p>
                  <p><strong>TL;DR:</strong> This talk addresses the vulnerability of neural network explanations to imperceptible input perturbations. The authors propose a training methodology that enhances attributional robustness by aligning input gradients spatially with the original image, utilizing a soft-margin triplet loss. Their approach not only improves the stability of attribution maps but also enhances performance in weakly supervised object localization tasks.</p>
                  <p><strong>Keywords:</strong> Attributional Robustness, Interpretability, Neural Networks, Input-Gradient Alignment, Soft-Margin Triplet Loss, Weakly Supervised Object Localization</p>
                </div>
              </div>
              
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=iztoG3uH7aY" target="_blank">
                <img src="https://img.youtube.com/vi/iztoG3uH7aY/hqdefault.jpg" alt="Siam R-CNN - Visual Tracking by Re-Detection">
              </a>
              <div class="talk-details">
                <h5>Siam R-CNN - Visual Tracking by Re-Detection</h5>
                <p><strong>Author:</strong>Jonathon Luiten, PhD @ RWTH Aachen + Carnegie Mellon + Uni Oxford, Research Scientist at Meta Reality Labs                </p>
                <p><strong>TL;DR:</strong>This presentation introduces Siam R-CNN, a framework that combines Siamese networks with region-based convolutional neural networks for robust visual tracking through re-detection mechanisms.</p>
                <p><strong>Keywords:</strong> Visual tracking, Siamese networks, R-CNN, re-detection</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=1YEPqyTaL4M" target="_blank">
                <img src="https://img.youtube.com/vi/1YEPqyTaL4M/hqdefault.jpg" alt="Full-Body Awareness from Partial Observations">
              </a>
              <div class="talk-details">
                <h5>Full-Body Awareness from Partial Observations</h5>
                <p><strong>Author:</strong> Chris Rockwell, PhD @University of Michigan</p>
                <p><strong>TL;DR:</strong> This talk explores methods to achieve full-body awareness in systems from partial observations, enhancing the understanding and prediction of human poses in various applications.</p>
                <p><strong>Keywords:</strong> Full-body awareness, partial observations, human pose estimation</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=11_GWjoCtd4" target="_blank">
                <img src="https://img.youtube.com/vi/11_GWjoCtd4/hqdefault.jpg" alt="Real- Time Sign Language Detection for Video Conferencing Applications.">
              </a>
              <div class="talk-details">
                <h5>Real- Time Sign Language Detection for Video Conferencing Applications.</h5>
                <p><strong>Author:</strong> Amit Moryossef, PhD @Bar-Ilan University +  Intern @Google Zurich  </p>
                <p><strong>TL;DR:</strong> This presentation discusses the development of real-time sign language detection systems tailored for video conferencing platforms, aiming to improve accessibility and communication.</p>
                <p><strong>Keywords:</strong> Sign language detection, real-time systems, video conferencing, accessibility</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=5u3uRLbL9HE" target="_blank">
                <img src="https://img.youtube.com/vi/5u3uRLbL9HE/hqdefault.jpg" alt="Butterflies in Hyperbolic Space : Leveraging Label Hierarchy to Improve Image Classification">
              </a>
              <div class="talk-details">
                <h5>Butterflies in Hyperbolic Space : Leveraging Label Hierarchy to Improve Image Classification</h5>
                <p><strong>Ankit Dhall, Graduate Student, Robotic Systems and Control @ETH Zurich</strong> TBD</p>
                <p><strong>TL;DR:</strong>​The paper proposes methods to enhance image classification by incorporating the semantic hierarchy of class labels. The authors introduce order-preserving embeddings, utilizing both Euclidean and hyperbolic geometries, to model label-label and label-image interactions. These approaches are validated on the ETHEC dataset, demonstrating improved performance over hierarchy-agnostic models. </p>
                <p><strong>Keywords:</strong> Hyperbolic Space, Label Hierarchy, Image Classification, Order-Preserving Embeddings, Euclidean Geometry, Hierarchical Learning, Semantic Relationships, ETHEC Dataset</p>
              </div>
            </div>
          
            <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=WpiX93eNrt4" target="_blank">
                  <img src="https://img.youtube.com/vi/WpiX93eNrt4/hqdefault.jpg" alt="GradSLAM: Differentiable Dense SLAM">
                </a>
                <div class="talk-details">
                  <h5>GradSLAM: Differentiable Dense SLAM</h5>
                  <p><strong>Author:</strong> Krishna Murthy Jatavallabhula, Ganesh Iyer, and Liam Paull</p>
                  <p><strong>TL;DR:</strong> gradSLAM is a fully differentiable dense simultaneous localization and mapping (SLAM) framework that integrates gradient-based learning with SLAM systems. By making SLAM components differentiable, it allows for end-to-end optimization, enabling gradients to flow from 3D maps back to 2D sensor inputs. :contentReference[oaicite:0]{index=0}</p>
                  <p><strong>Keywords:</strong> Differentiable SLAM, Automatic Differentiation, Dense Mapping, Gradient-Based Learning, Computational Graphs</p>
                </div>
              </div>
          
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=whOdg-yrgdI" target="_blank">
                  <img src="https://img.youtube.com/vi/whOdg-yrgdI/hqdefault.jpg" alt="Mish: A Self Regularized Non-Monotonic Activation Function">
                </a>
                <div class="talk-details">
                  <h5>Mish: A Self Regularized Non-Monotonic Activation Function</h5>
                  <p><strong>Author:</strong> Diganta Misra</p>
                  <p><strong>TL;DR:</strong> Mish is a novel neural activation function defined as f(x) = x * tanh(softplus(x)). It is smooth, continuous, and non-monotonic, offering advantages over traditional functions like ReLU and Swish. Empirical results demonstrate that networks utilizing Mish achieve higher accuracy and better generalization across various benchmarks. :contentReference[oaicite:1]{index=1}</p>
                  <p><strong>Keywords:</strong> Activation Function, Neural Networks, Deep Learning, Non-Monotonic Function, Smooth Activation</p>
                </div>
              </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=UTIQpGO2dek" target="_blank">
                <img src="https://img.youtube.com/vi/UTIQpGO2dek/hqdefault.jpg" alt="Hand-Object Contact During Grasping: Capture, Analysis and Applications">
              </a>
              <div class="talk-details">
                <h5>Hand-Object Contact During Grasping: Capture, Analysis and Applications</h5>
                <p><strong>Author:</strong> Samarth Brahmbhatt, Postdoctoral researcher at Intelligent Systems lab at Intel in Santa Clara </p>
                <p><strong>TL;DR:</strong> This talk focuses on the methodologies for capturing and analyzing hand-object contact during grasping tasks. It explores the applications of this analysis in improving robotic manipulation and understanding human grasping behaviors.</p>
                <p><strong>Keywords:</strong> Hand-Object Interaction, Grasping, Contact Analysis, Robotic Manipulation, Human-Computer Interaction</p>
            </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=M4Sb8SQh6Uc" target="_blank">
                <img src="https://img.youtube.com/vi/M4Sb8SQh6Uc/hqdefault.jpg" alt="Improving Machine Vision using Human Perceptual Representations">
              </a>
              <div class="talk-details">
                <h5>Improving Machine Vision using Human Perceptual Representations</h5>
                <p><strong>Author:</strong> Pramod RT, Postdoctoral Researcher @MIT</p>
                <p><strong>TL;DR:</strong> This presentation discusses leveraging human perceptual representations to enhance machine vision systems. By integrating insights from human perception, the talk highlights strategies to improve the accuracy and robustness of computer vision models.</p>
                <p><strong>Keywords:</strong> Machine Vision, Human Perception, Perceptual Representations, Visual Processing</p>
              </div>
            </div>
          
            <div class="talk-entry">
              <a href="https://www.youtube.com/watch?v=A-UqKhe5f0I" target="_blank">
                <img src="https://img.youtube.com/vi/A-UqKhe5f0I/hqdefault.jpg" alt="Learning Data Augmentation  Using Online BiLevel Data Optimisation for Image Classification">
              </a>
              <div class="talk-details">
                <h5>Learning Data Augmentation  Using Online BiLevel Data Optimisation for Image Classification</h5>
                <p><strong>Author:</strong> Issam Laradji @ElementAI/ServiceNow Research + Saypraseuth Mounsaveng, PhD @ETS Montreal</p>
                <p><strong>TL;DR:</strong> The talk introduces an online bi-level optimization approach to learn data augmentation policies for image classification tasks. This method aims to enhance model generalization by optimizing augmentation strategies during training.</p>
                <p><strong>Keywords:</strong> Data Augmentation, Bi-Level Optimization, Image Classification, Machine Learning, Model Generalization</p>
            </div>
            </div>
          
            <h2>Graduate Studies Series</h2>
            <div class="talks-list">
              <!-- Individual talk entries -->
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=3FQg42M_1eQ" target="_blank">
                  <img src="https://img.youtube.com/vi/3FQg42M_1eQ/hqdefault.jpg" alt="Masters (MS) in CS in USA">
                </a>
                <div class="talk-details">
                  <h5>Masters (MS) in CS in USA | MITACS Globalink Research Internship | MS in NYU</h5>
                  <p><strong>Author:</strong> Sidharth Purohit</p>
                  <p><strong>TL;DR:</strong> This webinar provides insights into pursuing a Master's degree in Computer Science in the USA, covering application processes, program structures, and opportunities available to students.</p>
                  <p><strong>Keywords:</strong> MS in Computer Science, USA, Graduate Studies, Application Process, Program Structure</p>
                </div>
              </div>
            
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=zh01rw9GlTI" target="_blank">
                  <img src="https://img.youtube.com/vi/zh01rw9GlTI/hqdefault.jpg" alt="Graduate School Applications">
                </a>
                <div class="talk-details">
                  <h5>Graduate School Applications | Fully Funded Masters + PhD | IELTS vs TOEFL | Statement of Purpose</h5>
                  <p><strong>Author:</strong> Raman Dutt</p>
                  <p><strong>TL;DR:</strong> This session offers guidance on the graduate school application process, including tips on crafting compelling statements of purpose, securing strong recommendation letters, and avoiding common pitfalls.</p>
                  <p><strong>Keywords:</strong> Graduate Applications, Statements of Purpose, Recommendation Letters, Application Tips</p>
                </div>
              </div>
            
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=fiw3YYWdTTI" target="_blank">
                  <img src="https://img.youtube.com/vi/fiw3YYWdTTI/hqdefault.jpg" alt="Research Scholarships for Undergrads, DAAD WISE (Uni of Hamburg), IAS SRFP, Job as SDE @Microsoft">
                </a>
                <div class="talk-details">
                  <h5>Research Scholarships for Undergrads, DAAD WISE (Uni of Hamburg), IAS SRFP, Job as SDE @Microsoft</h5>
                  <p><strong>Author:</strong> Shravan Nayak</p>
                  <p><strong>TL;DR:</strong> This webinar discusses various research scholarships available for undergraduates, such as DAAD WISE and IAS SRFP, and shares insights into securing positions like Software Development Engineer at Microsoft.</p>
                  <p><strong>Keywords:</strong> Undergraduate Research Scholarships, DAAD WISE, IAS SRFP, Microsoft SDE, Career Opportunities</p>
                </div>
              </div>
            
              <div class="talk-entry">
                <a href="https://www.youtube.com/watch?v=E8XLo2PlNsw" target="_blank">
                  <img src="https://img.youtube.com/vi/E8XLo2PlNsw/hqdefault.jpg" alt="PhD in USA">
                </a>
                <div class="talk-details">
                  <h5>PhD in USA | Fully Funded PhD @UCSC | Cold Mailing | Research Internship @GeorgiaTech, IISc                </h5>
                  <p><strong>Author:</strong> Sai Siddartha Maram</p>
                  <p><strong>TL;DR:</strong> This webinar provides an overview of pursuing a PhD in the USA, discussing application strategies, funding opportunities, and insights into the life of a doctoral student.</p>
                  <p><strong>Keywords:</strong> PhD Programs, USA, Doctoral Studies, Application Strategies, Funding Opportunities</p>
                </div>
              </div>
            </div>
                      
          </article>          
      </div>
    </div>
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; 2025 Shambhavi Mishra.
        Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.
      </div>
    </footer>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"></script>
  </body>
</html>
